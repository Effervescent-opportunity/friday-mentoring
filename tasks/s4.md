## Обязательные задачи

Предположим, что происходит интеграция с [SIEM](https://encyclopedia.kaspersky.com/glossary/siem/) системой, которая принимает ряд событий через Kafka в формате `application/json` (UTF-8). Для упрощения задачи представим невероятное, что трансформация сообщений в целевой формат происходит на принимающей стороне, поэтому структура отправляемых сообщений остаётся на усмотрение разработчика.

### 1. С помощью Spring Kafka нужно реализовать отправку событий:
  - об успешном входе;
  - о неуспешном входе.

Под входом в систему может пониматься вызов API auth/login или возникновение [AuditApplicationEvent](https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#actuator.auditing.custom) или что угодно ещё на усмотрение разработчика.

**Детали**:
  - для локальной работы с kafka потребуется создать docker-compose файл, где используется Kafka последней (на момент выполнения задачи) версии. Версию нужно указывать явным образом, не `latest`;
  - сообщение должно содержать как минимум IPv4 адрес, время, логин, вид события;
  - ради упрощения задачи **не рассматриваются** особенности получения реального IP через [XFF](https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties.server.server.forward-headers-strategy) и настройки балансировщика;
  - корректность реализации должна быть подтверждена тестами на основной сценарий и граничные случаи.

## Опциональные задачи

### 1. Для выполненной интеграции с Kafka:
  - нужно оценить реализацию с точки зрения надёжности и отказоустойчивости (могут ли теряться сообщения при отправке - если да, то при каких случаях);
  - если такие случаи будут найдены, нужно предложить решения.

## Что изучается/демонстрируется
  - Spring Boot Kafka (producer);
  - опционально: форматы сериализации сообщений (json, thrift, avro, protobuf)
  - опционально: событийная модель Spring Security;
  - опционально: Spring Boot Actuator.
  
## Warning:
Задача большая, если подходить к изучению предметно, поэтому граничные случаи будем рассматривать в следующих сериях: на первом этапе требуется *базовая* реализация, которая всего лишь отправляет сообщения в Kafka, если брокер доступен — основной сценарий (и не отправляет, если недоступен — граничный случай).

На этом этапе нужно максимально воздержаться от других технологий (JPA, AOP) и вводить их по мере явной необходимости.  