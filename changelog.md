
## Десятое задание

- Swagger UI находится по адресу: https://localhost:8443/swagger-ui/index.html#
- Индексы не добавлены, так как неизвестно, запросы с какими полями будут чаще всего
- Сортировка и пагинация сделаны через отдельные параметры, а не через `Pageable`, потому что `Pageable` на некорректных значениях
параметров не возвращает ошибку, а подменяет их параметрами по умолчанию
- Возвращаю Spring'овый `Page`, потому что так было проще и явного указания возвращать не его не было
- Возвращаю фактический тип события из базы, совпадающий с AuthEventType, потому что так проще и явного указания, что UI относится к SIEM не было
- Не нравится, что уже три приватных record `AuthEventDto`, но пока не придумала, как их объединить и куда положить

## Восьмое задание

- AuthEventRepository оставлен публичным для интеграционных тестов
- Удалены `CustomJsonSerializer`, `KafkaSenderTest`
- Исправлен порт для `KafkaTest`, без этого он падал при поднятых контейнерах из docker compose
- Обновлена версия gradle до 8.3 в `Dockerfile`
- Исправлены замечания по [s8_review.md](tasks/s8_review.md)

## Седьмое задание

- Убрана проверка доступности Kafka перед отправкой, потому что "при недоступности Кафки send() вызовет immediate failure с выбросом исключения => в реализации можно убрать"
- Убрано сохранение сущностей в отдельной транзакции, потому что "если использовать @Transactional, то TransactionTemplate не нужен => тесты можно написать более эффективно", а изменение поведения будет исправлено при рефакторинге
- Для поля `createdAt` значение по умолчению вынесено из конструктора в объявление поля, потому что есть еще дефолтный конструктор, и лучше так, чем дублировать в конструкторах
- По поводу холивара про создание интерфейса с одной реализацией, в конкретно моем случае есть смысл сделать такой интерфейс для отправки
  сообщений аудита куда-то, какой-нибудь MessageSender, с одним, максимум двумя методами, - отправкой сообщения куда-то и проверкой, что оно доступно.
  И в целом вся статья про то, что интерфейсы нужны лишь если планируются улучшения/доработки в конкретных местах (хотя ладно, в рабочей реальности реально
  может понадобиться доработать все, пора бы уже привыкнуть к этому). И тогда идея делать интерфейс для уменьшения связности (?), закрепления контракта, тестирования
  и намечания планов - хороша. Но да, вообще не на все

### Оценка покрытия и реалистичности проверки тестами для сервисного слоя
- Сейчас у меня покрытие юнит тестами для `service` - 88%, вместе с интеграционными - 98%, нет теста на "Кафка доступна, но при отправке туда ошибка"
- Можно написать тесты, которые будут покрывать 100% кода, и которые будут чисто формальными "тестами ради тестов", просто проходя по всем веткам сервиса, даже нереалистичным. 
Такое иногда практикуется, когда нужно достичь покрытия тестов ХХ% для прохождения quality gate для merge/pull request'ов
- Можно написать нереалистичные тесты, например подавая на вход метода (например AuthEventService.processEvent) null, чего не может произойти при запуске приложения
- Такими юнит тестами не протестировать взаимодействие сервисов и происходящее "под капотом" - аспекты, event'ы, контексты, транзакции - сам Spring или Flyway, например. 
А часто важно именно это, что при попытке залогиниться под несуществующим пользователм, будет ответ 401 и создастся event AUTHENTICATION_FAILURE
- Отмечу еще проблему с юнит тестами - их довольно скучно писать, даже любящей закопаться в незначительные детали и пройтись по всем веткам реализации мне

## Шестое задание

- Разделение тестов на "мелкие" и "крупные" сделано через отдельный sourceSet для крупных тестов, потому что не хочется добавлять теги на
каждый тест (легко забыть), фильтровать по названию. Вариант с отдельным source set'ом кажется наиболее удобным с точки зрения разработки и 
разделения зависимостей. Был еще вариент с test suite, но не получилось до конца понять, что это и зачем, если можно без него
- Для "крупных" тестов установлено failFast = true, потому что в рабочей реальности бывает нужно как можно быстрее узнать, что что-то не работает, а не ждать, пока пройдут все
- Для "мелких" и "крупных" тестов генерятся отдельные `*.exec` файлы в `build/jacoco`, задача `jacocoTestReport` запустит тесты и сделает общий html-отчет 
по покрытию в `build/reports/jacoco/all/index.html`, если убрать задание этого пути, то в `build/reports/jacoco/test/html/index.html` 
- Задача `allTestsReport` запустит тесты и сделает общий html-отчет по запуску тестов в `build/reports/allTests/index.html`
- Задача `jacocoTestCoverageVerification` запустит тесты и упадет, если покрытие тестами каждого класса (кроме всех entity и Application) меньше 80%
- Сейчас отчеты и проверки покрытия не запускаются при запуске задачи `build`, если нужно запустить, то добавить эти задачи в `check.dependsOn`
- Есть очень странная проблема - при запуске задачи, включающей в себя выполнение integrationTest, в лог пишется строк 20 консольного вывода тестов, хотя не должно
- Не получилось сделать разделение логов в отчете по отдельным тестам. В xml файлах разделены, в html-отчете уже нет

## Пятое задание

- По умолчанию у Кафки гарантии доставки at least once, поэтому в конфигах только идемпотентность добавлена (на случай дублирования отправки, что допускается паттерном)
- Для публикации сообщений в Кафку используется паттерн [Polling publisher](https://microservices.io/patterns/data/polling-publisher.html), по сути просто шедулер.
  Используется он, а не Transaction log tailing, потому что базонезависим
- Выбрана БД Postgres, потому что с ней я работала, плюс она бесплатна и используется много где, в том числе на текущем месте работы. Плюс поддерживает ACID
- База использует volume, чтобы при перезапуске Докера данные сохранялись на хосте, где запускается Докер
- Создание таблиц в базе с помощью initdb.sql, а не flyway\liquibase, потому что их добавление займет время плюс неизвестно, будут ли еще задания на изменение схемы базы
- Добавлены две таблицы: auth_event и outbox, в первой хранятся все event'ы, вторая - для реализации паттернов Transactional outbox и Polling publisher, из нее будут удаляться записи при успешной отправке в Кафку
- Интеграционные тесты - KafkaTest, KafkaDisabledTest. Для шедулера только юнит тест, так как я не знаю, как включить Кафку в середине теста и стоит ли

### Обоснование с точки зрения надежности

Теперь все event'ы сохраняются в БД, есть переотправка не доставленных в течение какого-то промежутка времени. Что может пойти не так:
1. Может отказать база, тогда все данные потеряются и новые не запишутся (маловероятно, хотя в Докере легко это устроить)
2. Может отказать Кафка, тогда сообщения не будут отправляться, а будут копиться в outbox (высокая вероятность, для этого в переотправке выбираются все данные за какой-то промежуток времени)
3. Может появиться нагрузка на приложение, при которой что-то пойдет не так (маловероятно)
4. _Оставшиеся проблемы с неизвестной (маленькой?) вероятностью_: Сообщения могут теряться, если Кафка мне ответила успехом, а по факту не обработала. Не знаю, насколько они реальны
5. _Оставшиеся проблемы с неизвестной (маленькой?) вероятностью_: Отсутствие потребителя сообщений и потенциальное переполнение очереди
6. _Оставшиеся проблемы с неизвестной (маленькой?) вероятностью_: Отказ хоста с Докером, отказ хоста с приложением

Все вышеописанные сценарии маловероятны или учитываются в реализации, сделано все возможное для уменьшения рисков, так что в целом система достаточно надежная при отсутствии явных требований надежности.

## Дополнения к четвертому заданию

- Переделано создание топика, предыдущий вариант замедлял запуск приложения при отсутствии доступа к Кафке
- Для проверки доступности Кафки используется adminClient
- Исправлено наличие AUTHORIZATION_FAILURE event'ов, добавлен тест на отстутствие доступа к Кафке

## Четвёртое задание

- Подняты версии Spring Boot'а до 3.1.2, Spring Dependency Management Plugin'а до 1.1.2, версии в Dockerfile
- Выбран Docker-образ Kafka и Zookeeper от Confluentinc, потому что Confluentinc был создан теми же людьми, которые создали Kafka, почему бы не попробовать именно его
- Zookeeper, Kafka, Kafka UI в Docker'е, приложение не в нем, потому что были проблемы с доступом к нему в Docker'е, было принято решение сосредоточиться на выполнении основной логики задания
- Есть предположение, что Zookeeper в моем случае с 1 нодой всего не нужен, оно не проверялось. 1 нода всего потому что так проще и других требований не было
- События об успешной\неуспешной аутентификации и о неуспешной авторизации отправляются в топик `mentoring.auth.events`, он задается в application.properties
  (не было найдено best practices, как назвать саму проперти, поэтому примитивно). Событие успешной авторизации не отправляется, так как в случае
  корректной работы сервиса, таких событий будет больше 90%, и в этом нет смысла, плюс потому что его нет в auditevents Spring'а 
- Сериализация в JSON, потому что по условиям задачи система принимает `application/json`, плюс кажется, это самый используемый способ
- Можно посмотреть сообщения в топике через kafka-ui по адресу `localhost:8090`
- Можно запустить приложение из Intellij Idea сразу с Docker'ом, для этого в build.gradle в dependencies добавить 
строчку `developmentOnly 'org.springframework.boot:spring-boot-docker-compose'` (на `spring.boot.docker.compose` в application.properties ему параллельно внезапно, важно лишь, что в Gradle). 
Idea сама поднимет контейнеры одновременно со стартом приложения и остановит одновременно с остановкой (поэтому убрано, для разработки удобнее, когда контейнеры управляются отдельно)
- Граничный случай "не отправлять сообщения, если нет доступа к Кафке" не реализован, отправка просто падает с таймаутом - потому что 
времени разобраться, как проверить, что доступ есть, не хватило. Тесты, соответственно, только на случай "доступ к Кафке есть"
- Нет тестов на случай неуспешной авторизации для PreAuthorize - не создаются event'ы в тестах почему-то. Плюс возможны лишние параметры в конфигурации теста
- В CustomKafkaConfig только 1 бин, потому что предполагалось, что там будут еще бины для определения доступности Кафки, в KafkaProducer остался метод-заготовка для этого

### Опциональная задача

> Могут ли теряться сообщения и когда?

Быстрый ответ без проверки фактов и упорядочивания:

Сообщения могут теряться, если нет доступа к Кафке. И, вероятно, к Зукиперу тоже. Моя текущая реализация ничего не делает, если не получилось отправить (тайм-аут/ещё проблемы).

Вариант исправления: реализовать переотправку сообщений с каким-то интервалом в зависимости от типа ошибки. Тут возникают минимум две проблемы:
1. Сообщения могут дублироваться, если Кафка мне ответила ошибкой, а по факту обработала, и сработала переотправка; 
2. Сообщения могут теряться, если Кафка мне ответила успехом, а по факту не обработала. Не знаю, насколько они реальны, в какой конкретно момент отвечает Кафка, вероятно это можно исправить настройкой Кафки или нескольких ее подов (нод? Инстансов?)

Плюс сам способ реализации переотправки может добавить способов потери сообщений. Как я понимаю, должны быть какие-то требования 
к системе, и в зависимости от них реализуется переотправка и тд. Есть ли устаревание у сообщений, например.

Плюс нет потребителя сообщений, очередь может переполниться.

С учётом, что Кафка запускается в Докере, добавляются ещё проблемы. Можно, например, стереть всю информацию о контейнере одной командой, 
и все сообщения в очереди сотрутся. Вот это решается разраничением доступа - чтобы почти никто не мог этого сделать ни случайно, ни специально.
Ещё само приложение может перезапускаться/упасть, сервер остаться без электричества, например. Это тоже решается несколькими серверами в разных местах и настройкой, какие запросы куда ходят.

## Третье задание

- Сервис защищен @PreAuthorize, потому что @Secured считается Spring'ом legacy, а использовать @PreFilter - перебор, у меня нет списков для фильтрации.
Можно было бы сделать более сложную логику со специальными бинами или кастомными аннотациями, это тоже перебор относительно требуемого
- Добавлен PKCS12 keystore, команды для генерации ниже. Правда ощущение, что при запуске берется не из него. При старте приложения вот такая фраза в логах
`...o.a.t.util.net.NioEndpoint.certificate   : Connector [...], TLS virtual host [_default_], certificate type [UNDEFINED] configured from [/home/{user}/.keystore] using alias [tomcat]`
- Удален метод logout из AuthController, он был некорректный, надо было использовать SecurityContextLogoutHandler. Теперь по пути `/auth/logout` можно и GET, и POST-запросом делать logout
- Удалена аннотация @EnableWebSecurity, потому что работает и без нее (почему?)

#### Команды для создания pkcs12 keystore
Создать ключ и самоподписанный сертификат: 
`openssl req -x509 -newkey rsa:4096 -keyout FM-key.key -out FM-ss-cert.pem -days 365 -subj "/CN=localhost/"`

Создать PKCS12 keystore:
`openssl pkcs12 -export -in FM-ss-cert.pem -inkey FM-key.key -out FM-keystore.p12`

#### Команды curl
В предыдущих командых нужно заменить http на https и порт на 8443, добавить `-k`, чтобы curl пропускал самоподписанный сертификат.

`curl -k -v -X POST https://localhost:8443/auth/login -H "Content-Type: application/json" -d '{"user": "root", "password": "password"}'`

`curl -k -v https://localhost:8443/time/current/utc -H "Cookie: JSESSIONID=F12CC1A341A11E27B07289E26E540E43"`

`curl -k -v -X POST https://localhost:8443/auth/logout -H "Cookie: JSESSIONID=F12CC1A341A11E27B07289E26E540E43"`

`curl -k -v https://localhost:8443/auth/logout -H "Cookie: JSESSIONID=F12CC1A341A11E27B07289E26E540E43"`

## Второе задание

__Проблема__: у меня не получается по времени - на первое задание ушло около 9 часов суммарного времени, а там все темы так или иначе встречались
на работе или при самообучении. Spring Security - совсем новая для меня тема, плюс по личным причинам 3 дня не было возможности уделять
время обучению. В итоге на это так себе решение ушло 6 часов, и качество сильно хуже. __Можно ли выдавать задание на 2 недели или еще более легкое задание? Или двухступенчатое?__


- OAUTH не нужен, так как его ему нужно внешнее апи + его главная фича - возможность авторизовываться в нескольких местах, мне не надо
- В CustomSecurityConfig для AuthenticationEntryPoint выставлен HTTP код 404, потому что мне понравилась вычитанная идея скрывать страницы под этим кодом, как будто там ничего нет
- Чувствительная информация хранится прямо в коде, работы с header'ами нет по написанной выше причине
- Планировалось хоть как-то шифровать пароль, был выбран bcrypt, потому что он считается дефолтным
- Планировалось разобраться, почему возникает ситуация "я могу 3 раза залогиниться, получить 3 разных JSESSIONID, разлогиниться из одного, и другие останутся рабочими"
- Планировалось разобраться, что такое возможность rememberMe в конфиге, почему везде рекомендуют выключить csrf
- Планировалось разобраться, как exceptionHandling в конфиге соотносится с уже написанным мной ClockExceptionHandler
- Планировалось разобраться, как сделать https

Чтобы авторизоваться, надо отправить POST-запрос с header'ом `Content-Type: application/json` 
и body: `{"user": "root", "password": "password"}`
В header'е ответа придет header Set-Cookie (типа такого Set-Cookie: JSESSIONID=F78B79F2923D5192B59CED17CDC76BF3; Path=/; HttpOnly) с JSESSIONID, и для запросов в ClockController и logout нужно добвлять 
header вида `Cookie: JSESSIONID=F78B79F2923D5192B59CED17CDC76BF3`, значение JSESSIONID из ответа на авторизацию

#### Команды curl
`curl -v -X POST http://localhost:8080/auth/login -H "Content-Type: application/json" -d '{"user": "root", "password": "password"}'`

`curl -v http://localhost:8080/time/current/utc -H "Cookie: JSESSIONID=F12CC1A341A11E27B07289E26E540E43"`

`curl -v "http://localhost:8080/time/current?timezone=Europe/Paris" -H "Cookie: JSESSIONID=F12CC1A341A11E27B07289E26E540E43"`

## Первое задание

Дополнительное задание не сделано

- Выбран Spring Web, потому что Spring Reactive Web я вообще не знаю
- Java 17 liberica, потому что такая на реальной работе
- Gradle 8.2, потому что он новый и хочется его попробовать
- Alpine linux в Docker, потому что везде написано, что он меньше всего по размеру
- Кривой ClockExceptionHandler, потому что ни один из способов возвращать JSON 
и для строки с ошибкой, и для даты, не сработал, было принято решение оставить как есть
- compose.yaml пустой, потому что времени разобраться и написать уже не остается.
Контейнер именуется случайным образом самим Docker'ом.


